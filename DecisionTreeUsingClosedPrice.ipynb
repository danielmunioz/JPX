{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "567c2521-f4a8-41c2-980a-4b9bd7703557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import jpx_tokyo_market_stock_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7262670-40c1-4fa0-8446-9b5fe6ef7ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree using only 'Close' dropping nulls. Elapsed time: 23.791303157806396\n",
      "Mean Absolute Error: 0.020952688442143912\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "start = time.time()\n",
    "train_data = pd.read_csv(\"../tokyo/train_files/stock_prices.csv\",parse_dates=[\"Date\"])\n",
    "X = train_data.loc[:,(\"SecuritiesCode\",\"Close\",\"Target\")]\n",
    "X = X.dropna()\n",
    "#X.groupby(\"SecuritiesCode\").fillna(method=\"ffill\",inplace=True)\n",
    "y = X.pop(\"Target\")\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.1,random_state=0)\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf.fit(X_train,y_train)\n",
    "prediction = clf.predict(X_val)\n",
    "stop = time.time()\n",
    "print(f\"DecisionTree using columns: 'Close' dropping any nulls.\")\n",
    "print(f\"Dropping rows having nulls in columns: 'Close','Target'. Elapsed time: {stop-start}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_val,prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3f704d-c167-4290-89d6-801404a2849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 23:52:43.403983: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-16 23:52:43.404044: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import combinations\n",
    "\n",
    "class CombinatorialPurgedGroupKFold():\n",
    "    def __init__(self, n_splits = 6, n_test_splits = 2, purge = 1, pctEmbargo = 0.01, **kwargs):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_test_splits = n_test_splits\n",
    "        self.purge = purge\n",
    "        self.pctEmbargo = pctEmbargo\n",
    "        \n",
    "    def split(self, X, y = None, groups = None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "            \n",
    "        u, ind = np.unique(groups, return_index = True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_groups = len(unique_groups)\n",
    "        group_dict = {}\n",
    "        for idx in range(len(X)):\n",
    "            if groups[idx] in group_dict:\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "                \n",
    "        n_folds = comb(self.n_splits, self.n_test_splits, exact = True)\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "            \n",
    "        mbrg = int(n_groups * self.pctEmbargo)\n",
    "        if mbrg < 0:\n",
    "            raise ValueError(\n",
    "                \"The number of 'embargoed' groups should not be negative\")\n",
    "        \n",
    "        split_dict = {}\n",
    "        group_test_size = n_groups // self.n_splits\n",
    "        for split in range(self.n_splits):\n",
    "            if split == self.n_splits - 1:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):].tolist()\n",
    "            else:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):int((split + 1) * group_test_size)].tolist()\n",
    "        \n",
    "        for test_splits in combinations(range(self.n_splits), self.n_test_splits):\n",
    "            test_groups = []\n",
    "            banned_groups = []\n",
    "            for split in test_splits:\n",
    "                test_groups += split_dict[split]\n",
    "                banned_groups += unique_groups[split_dict[split][0] - self.purge:split_dict[split][0]].tolist()\n",
    "                banned_groups += unique_groups[split_dict[split][-1] + 1:split_dict[split][-1] + self.purge + mbrg + 1].tolist()\n",
    "            train_groups = [i for i in unique_groups if (i not in banned_groups) and (i not in test_groups)]\n",
    "\n",
    "            train_idx = []\n",
    "            test_idx = []\n",
    "            for train_group in train_groups:\n",
    "                train_idx += group_dict[train_group]\n",
    "            for test_group in test_groups:\n",
    "                test_idx += group_dict[test_group]\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae3bd0-6782-45bb-bb94-abaeedac8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 6\n",
    "n_test_splits = 1\n",
    "elements = list(range(10 * (n_splits + n_test_splits)))\n",
    "groups = [element // n_splits for element in elements]\n",
    "data = pd.DataFrame({\"group\": groups, \"element\": elements})\n",
    "kfold = CombinatorialPurgedGroupKFold(n_splits, n_test_splits)\n",
    "for index, (train_indices, test_indices) in enumerate(kfold.split(data, groups=data[\"group\"])):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Fold {index}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Train indices:\", train_indices, \"Length:\", len(train_indices))\n",
    "    print(\"Test Indices:\", test_indices, \"Length:\", len(test_indices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
