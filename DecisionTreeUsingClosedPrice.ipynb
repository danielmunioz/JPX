{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567c2521-f4a8-41c2-980a-4b9bd7703557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aef5ddf-a20c-428a-ba90-6a9aa44f20fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.332531e+06</td>\n",
       "      <td>2.324923e+06</td>\n",
       "      <td>2.324923e+06</td>\n",
       "      <td>2.324923e+06</td>\n",
       "      <td>2.324923e+06</td>\n",
       "      <td>2.332531e+06</td>\n",
       "      <td>2.332531e+06</td>\n",
       "      <td>18865.000000</td>\n",
       "      <td>2.332293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.894835e+03</td>\n",
       "      <td>2.594511e+03</td>\n",
       "      <td>2.626540e+03</td>\n",
       "      <td>2.561227e+03</td>\n",
       "      <td>2.594023e+03</td>\n",
       "      <td>6.919366e+05</td>\n",
       "      <td>1.000508e+00</td>\n",
       "      <td>22.017730</td>\n",
       "      <td>4.450962e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.404161e+03</td>\n",
       "      <td>3.577192e+03</td>\n",
       "      <td>3.619363e+03</td>\n",
       "      <td>3.533494e+03</td>\n",
       "      <td>3.576538e+03</td>\n",
       "      <td>3.911256e+06</td>\n",
       "      <td>6.773040e-02</td>\n",
       "      <td>29.882453</td>\n",
       "      <td>2.339879e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.301000e+03</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.785414e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.891000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.035000e+03</td>\n",
       "      <td>1.009000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>3.030000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-1.049869e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.238000e+03</td>\n",
       "      <td>1.812000e+03</td>\n",
       "      <td>1.834000e+03</td>\n",
       "      <td>1.790000e+03</td>\n",
       "      <td>1.811000e+03</td>\n",
       "      <td>1.071000e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.965000e+03</td>\n",
       "      <td>3.030000e+03</td>\n",
       "      <td>3.070000e+03</td>\n",
       "      <td>2.995000e+03</td>\n",
       "      <td>3.030000e+03</td>\n",
       "      <td>4.021000e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.053159e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.997000e+03</td>\n",
       "      <td>1.099500e+05</td>\n",
       "      <td>1.105000e+05</td>\n",
       "      <td>1.072000e+05</td>\n",
       "      <td>1.095500e+05</td>\n",
       "      <td>6.436540e+08</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>1070.000000</td>\n",
       "      <td>1.119512e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SecuritiesCode          Open          High           Low         Close  \\\n",
       "count    2.332531e+06  2.324923e+06  2.324923e+06  2.324923e+06  2.324923e+06   \n",
       "mean     5.894835e+03  2.594511e+03  2.626540e+03  2.561227e+03  2.594023e+03   \n",
       "std      2.404161e+03  3.577192e+03  3.619363e+03  3.533494e+03  3.576538e+03   \n",
       "min      1.301000e+03  1.400000e+01  1.500000e+01  1.300000e+01  1.400000e+01   \n",
       "25%      3.891000e+03  1.022000e+03  1.035000e+03  1.009000e+03  1.022000e+03   \n",
       "50%      6.238000e+03  1.812000e+03  1.834000e+03  1.790000e+03  1.811000e+03   \n",
       "75%      7.965000e+03  3.030000e+03  3.070000e+03  2.995000e+03  3.030000e+03   \n",
       "max      9.997000e+03  1.099500e+05  1.105000e+05  1.072000e+05  1.095500e+05   \n",
       "\n",
       "             Volume  AdjustmentFactor  ExpectedDividend        Target  \n",
       "count  2.332531e+06      2.332531e+06      18865.000000  2.332293e+06  \n",
       "mean   6.919366e+05      1.000508e+00         22.017730  4.450962e-04  \n",
       "std    3.911256e+06      6.773040e-02         29.882453  2.339879e-02  \n",
       "min    0.000000e+00      1.000000e-01          0.000000 -5.785414e-01  \n",
       "25%    3.030000e+04      1.000000e+00          5.000000 -1.049869e-02  \n",
       "50%    1.071000e+05      1.000000e+00         15.000000  0.000000e+00  \n",
       "75%    4.021000e+05      1.000000e+00         30.000000  1.053159e-02  \n",
       "max    6.436540e+08      2.000000e+01       1070.000000  1.119512e+00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"tokyo/train_files/stock_prices.csv\")\n",
    "X = train_data[\"Close\"]\n",
    "y = train_data[\"Target\"]\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3f704d-c167-4290-89d6-801404a2849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 00:02:27.226575: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-03 00:02:27.226740: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import combinations\n",
    "\n",
    "class CombinatorialPurgedGroupKFold():\n",
    "    def __init__(self, n_splits = 6, n_test_splits = 2, purge = 1, pctEmbargo = 0.01, **kwargs):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_test_splits = n_test_splits\n",
    "        self.purge = purge\n",
    "        self.pctEmbargo = pctEmbargo\n",
    "        \n",
    "    def split(self, X, y = None, groups = None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "            \n",
    "        u, ind = np.unique(groups, return_index = True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_groups = len(unique_groups)\n",
    "        group_dict = {}\n",
    "        for idx in range(len(X)):\n",
    "            if groups[idx] in group_dict:\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "                \n",
    "        n_folds = comb(self.n_splits, self.n_test_splits, exact = True)\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "            \n",
    "        mbrg = int(n_groups * self.pctEmbargo)\n",
    "        if mbrg < 0:\n",
    "            raise ValueError(\n",
    "                \"The number of 'embargoed' groups should not be negative\")\n",
    "        \n",
    "        split_dict = {}\n",
    "        group_test_size = n_groups // self.n_splits\n",
    "        for split in range(self.n_splits):\n",
    "            if split == self.n_splits - 1:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):].tolist()\n",
    "            else:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):int((split + 1) * group_test_size)].tolist()\n",
    "        \n",
    "        for test_splits in combinations(range(self.n_splits), self.n_test_splits):\n",
    "            test_groups = []\n",
    "            banned_groups = []\n",
    "            for split in test_splits:\n",
    "                test_groups += split_dict[split]\n",
    "                banned_groups += unique_groups[split_dict[split][0] - self.purge:split_dict[split][0]].tolist()\n",
    "                banned_groups += unique_groups[split_dict[split][-1] + 1:split_dict[split][-1] + self.purge + mbrg + 1].tolist()\n",
    "            train_groups = [i for i in unique_groups if (i not in banned_groups) and (i not in test_groups)]\n",
    "\n",
    "            train_idx = []\n",
    "            test_idx = []\n",
    "            for train_group in train_groups:\n",
    "                train_idx += group_dict[train_group]\n",
    "            for test_group in test_groups:\n",
    "                test_idx += group_dict[test_group]\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1ae3bd0-6782-45bb-bb94-abaeedac8099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
      "tf.Tensor([999   2   3   4], shape=(4,), dtype=int32)\n",
      "tf.Tensor([  1 999   3   4], shape=(4,), dtype=int32)\n",
      "tf.Tensor([  1   2 999   4], shape=(4,), dtype=int32)\n",
      "tf.Tensor([  1   2   3 999], shape=(4,), dtype=int32)\n",
      "tf.Tensor([999 999 999 999], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "record_defaults = [999,999,999,999]\n",
    "dataset = tf.data.experimental.CsvDataset(\"missing.csv\", record_defaults)\n",
    "\n",
    "dataset = dataset.map(lambda *items: tf.stack(items))\n",
    "for line in dataset:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c3380a-1cef-4bff-b931-b1e0d97bccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=999>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=999>, <tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=999>, <tf.Tensor: shape=(), dtype=int32, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=999>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=999>, <tf.Tensor: shape=(), dtype=int32, numpy=999>, <tf.Tensor: shape=(), dtype=int32, numpy=999>, <tf.Tensor: shape=(), dtype=int32, numpy=999>)\n"
     ]
    }
   ],
   "source": [
    "for line in dataset:\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c53bd4-0df5-4da6-8a54-cded8564947a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
